{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697200e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, accuracy_score, f1_score,\n",
    "    confusion_matrix, roc_curve, auc, log_loss\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 1) File paths for 5 classes\n",
    "# ----------------------------\n",
    "paths = {\n",
    "    'bicep': 'imu_bicep_m0.csv',\n",
    "    'tricep': 'imu_tricep_m1.csv',\n",
    "    'overheadpress': 'imu_overheadpress_m2.csv',\n",
    "    'jump': 'imu_jump_m3.csv',\n",
    "    'squat': 'imu_squat_m4.csv'\n",
    "}\n",
    "\n",
    "# CSVs have no header row; enforce column names:\n",
    "colnames = [\"timestamp\",\"ax\",\"ay\",\"az\",\"gx\",\"gy\",\"gz\",\"roll\",\"pitch\",\"yaw\"]\n",
    "channels = [\"ax\",\"ay\",\"az\",\"gx\",\"gy\",\"gz\",\"roll\",\"pitch\",\"yaw\"]\n",
    "\n",
    "dfs = {label: pd.read_csv(p, header=None, names=colnames) for label, p in paths.items()}\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Windowing (100 Hz IMU)\n",
    "# ----------------------------\n",
    "FS = 100\n",
    "WIN = 100      # 1 second window\n",
    "STRIDE = 50    # 0.5 second overlap\n",
    "\n",
    "def window_featurize(df, label, win=WIN, stride=STRIDE):\n",
    "    \"\"\"\n",
    "    Convert a time-series file into windowed feature vectors.\n",
    "    Features per channel: mean, std, min, max, mean-square (energy proxy)\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for start in range(0, len(df) - win + 1, stride):\n",
    "        w = df.iloc[start:start+win]\n",
    "        feats = []\n",
    "        for c in channels:\n",
    "            x = w[c].astype(float).to_numpy()\n",
    "            feats.extend([\n",
    "                x.mean(),\n",
    "                x.std(ddof=0),\n",
    "                x.min(),\n",
    "                x.max(),\n",
    "                np.mean(x**2)\n",
    "            ])\n",
    "        X.append(feats)\n",
    "        y.append(label)\n",
    "    return np.array(X, dtype=np.float32), np.array(y)\n",
    "\n",
    "X_list, y_list = [], []\n",
    "for label, df in dfs.items():\n",
    "    Xw, yw = window_featurize(df, label)\n",
    "    X_list.append(Xw)\n",
    "    y_list.append(yw)\n",
    "\n",
    "X = np.vstack(X_list)\n",
    "y = np.concatenate(y_list)\n",
    "\n",
    "print(\"Total windows:\", X.shape[0], \"Feature dimension:\", X.shape[1])\n",
    "print(\"Class counts:\", dict(zip(*np.unique(y, return_counts=True))))\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Split 60/20/20\n",
    "# ----------------------------\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.40, random_state=42, stratify=y\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"Split sizes:\", len(y_train), len(y_val), len(y_test))\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Hyperparameter sweep (tune by validation log loss)\n",
    "# ----------------------------\n",
    "C_grid = [0.1, 1, 10, 100]\n",
    "gamma_grid = [\"scale\", 0.01, 0.1, 1]\n",
    "\n",
    "records = []\n",
    "best = None\n",
    "\n",
    "for C in C_grid:\n",
    "    for gamma in gamma_grid:\n",
    "        svm = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", SVC(kernel=\"rbf\", C=C, gamma=gamma, probability=True, random_state=42))\n",
    "        ])\n",
    "        svm.fit(X_train, y_train)\n",
    "        val_proba = svm.predict_proba(X_val)\n",
    "        ll = log_loss(y_val, val_proba, labels=svm.named_steps[\"clf\"].classes_)\n",
    "        records.append({\"C\": C, \"gamma\": str(gamma), \"val_log_loss\": ll})\n",
    "        if best is None or ll < best[\"val_log_loss\"]:\n",
    "            best = {\"C\": C, \"gamma\": gamma, \"val_log_loss\": ll}\n",
    "\n",
    "records = pd.DataFrame(records).sort_values(\"val_log_loss\").reset_index(drop=True)\n",
    "print(\"\\nTop sweep results:\\n\", records.head(10))\n",
    "print(\"\\nBest params:\", best)\n",
    "\n",
    "# Train best SVM\n",
    "svm_best = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", SVC(kernel=\"rbf\", C=best[\"C\"], gamma=best[\"gamma\"], probability=True, random_state=42))\n",
    "])\n",
    "svm_best.fit(X_train, y_train)\n",
    "\n",
    "# ----------------------------\n",
    "# 5) Test metrics\n",
    "# ----------------------------\n",
    "y_pred = svm_best.predict(X_test)\n",
    "proba = svm_best.predict_proba(X_test)\n",
    "class_order = svm_best.named_steps[\"clf\"].classes_.tolist()\n",
    "\n",
    "acc  = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "rec  = recall_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "f1   = f1_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "ll   = log_loss(y_test, proba, labels=class_order)\n",
    "\n",
    "print(\"\\n=== Test Metrics (Macro Avg) ===\")\n",
    "print(\"Accuracy :\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall   :\", rec)\n",
    "print(\"F1-score :\", f1)\n",
    "print(\"Log Loss :\", ll)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred, labels=class_order)\n",
    "print(\"\\nConfusion matrix (rows=true, cols=pred), labels =\", class_order)\n",
    "print(cm)\n",
    "\n",
    "# ----------------------------\n",
    "# 6) Save visuals (must include '_svm_')\n",
    "# ----------------------------\n",
    "out_dir = \"\"\n",
    "roc_path  = os.path.join(out_dir, \"roc_auc_svm_test.png\")\n",
    "ll_path   = os.path.join(out_dir, \"logloss_svm_heatmap.png\")\n",
    "viz_path  = os.path.join(out_dir, \"decision_regions_svm_pca_svm.png\")  # includes _svm_\n",
    "\n",
    "# ROC-AUC curves (multiclass one-vs-rest)\n",
    "y_test_bin = label_binarize(y_test, classes=class_order)\n",
    "\n",
    "plt.figure()\n",
    "for i, lab in enumerate(class_order):\n",
    "    fpr, tpr, _ = roc_curve(y_test_bin[:, i], proba[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f\"{lab} (AUC={roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], \"--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curves (One-vs-Rest) - SVM - Test Set\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(roc_path, dpi=200)\n",
    "plt.show()\n",
    "\n",
    "# Log loss heatmap over (C, gamma)\n",
    "gamma_labels = [str(g) for g in gamma_grid]\n",
    "C_labels = [str(c) for c in C_grid]\n",
    "heat = np.zeros((len(C_grid), len(gamma_grid)), dtype=float)\n",
    "\n",
    "def gamma_to_idx(g):\n",
    "    if g == \"scale\":\n",
    "        return gamma_grid.index(\"scale\")\n",
    "    return gamma_grid.index(float(g))\n",
    "\n",
    "for _, r in records.iterrows():\n",
    "    i = C_grid.index(float(r[\"C\"]))\n",
    "    j = gamma_to_idx(str(r[\"gamma\"]))\n",
    "    heat[i, j] = float(r[\"val_log_loss\"])\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.imshow(heat, interpolation=\"nearest\")\n",
    "plt.xticks(range(len(gamma_grid)), gamma_labels)\n",
    "plt.yticks(range(len(C_grid)), C_labels)\n",
    "plt.xlabel(\"gamma\")\n",
    "plt.ylabel(\"C\")\n",
    "plt.title(\"Validation Log Loss Heatmap (SVM RBF)\")\n",
    "for i in range(len(C_grid)):\n",
    "    for j in range(len(gamma_grid)):\n",
    "        plt.text(j, i, f\"{heat[i,j]:.3f}\", ha=\"center\", va=\"center\")\n",
    "plt.colorbar(label=\"Log Loss\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(ll_path, dpi=200)\n",
    "plt.show()\n",
    "\n",
    "# Visualize the SVM model: decision regions in 2D PCA space (for teaching)\n",
    "le = LabelEncoder()\n",
    "y_train_num = le.fit_transform(y_train)\n",
    "\n",
    "scaler = svm_best.named_steps[\"scaler\"]\n",
    "X_train_s = scaler.transform(X_train)\n",
    "\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X2 = pca.fit_transform(X_train_s)\n",
    "\n",
    "viz_clf = SVC(kernel=\"rbf\", C=best[\"C\"], gamma=best[\"gamma\"])\n",
    "viz_clf.fit(X2, y_train_num)\n",
    "\n",
    "x_min, x_max = X2[:, 0].min() - 1, X2[:, 0].max() + 1\n",
    "y_min, y_max = X2[:, 1].min() - 1, X2[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 400),\n",
    "                     np.linspace(y_min, y_max, 400))\n",
    "Z = viz_clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.contourf(xx, yy, Z.astype(float), alpha=0.25)\n",
    "for k, lab in enumerate(le.classes_):\n",
    "    mask = (y_train_num == k)\n",
    "    plt.scatter(X2[mask, 0], X2[mask, 1], s=10, label=lab)\n",
    "plt.title(\"SVM Decision Regions in 2D PCA Space (Visualization)\")\n",
    "plt.xlabel(\"PCA-1\")\n",
    "plt.ylabel(\"PCA-2\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(viz_path, dpi=200)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSaved figures:\")\n",
    "print(\" \", roc_path)\n",
    "print(\" \", ll_path)\n",
    "print(\" \", viz_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
