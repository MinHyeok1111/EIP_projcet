{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbde5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, label_binarize\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, roc_curve, auc, log_loss\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1) Load your 5 class CSVs (NO headers assumed)\n",
    "# ---------------------------------------------------------\n",
    "paths = {\n",
    "    'bicep': 'imu_bicep_m0.csv',\n",
    "    'tricep': 'imu_tricep_m1.csv',\n",
    "    'overheadpress': 'imu_overheadpress_m2.csv',\n",
    "    'jump': 'imu_jump_m3.csv',\n",
    "    'squat': 'imu_squat_m4.csv'\n",
    "}\n",
    "\n",
    "colnames  = [\"timestamp\",\"ax\",\"ay\",\"az\",\"gx\",\"gy\",\"gz\",\"roll\",\"pitch\",\"yaw\"]\n",
    "channels  = [\"ax\",\"ay\",\"az\",\"gx\",\"gy\",\"gz\",\"roll\",\"pitch\",\"yaw\"]\n",
    "\n",
    "dfs = {label: pd.read_csv(p, header=None, names=colnames) for label, p in paths.items()}\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2) Windowed feature extraction (recommended for 100 Hz IMU)\n",
    "# ---------------------------------------------------------\n",
    "FS = 100\n",
    "WIN = 100     # 1 second window\n",
    "STRIDE = 50   # 0.5 sec overlap\n",
    "\n",
    "def window_featurize(df, label, win=WIN, stride=STRIDE):\n",
    "    \"\"\"\n",
    "    For each window, compute per-channel features:\n",
    "    mean, std, min, max, mean-square (energy proxy)\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for start in range(0, len(df) - win + 1, stride):\n",
    "        w = df.iloc[start:start+win]\n",
    "        feats = []\n",
    "        for c in channels:\n",
    "            x = w[c].astype(float).to_numpy()\n",
    "            feats.extend([x.mean(), x.std(ddof=0), x.min(), x.max(), np.mean(x**2)])\n",
    "        X.append(feats)\n",
    "        y.append(label)\n",
    "    return np.asarray(X, dtype=np.float32), np.asarray(y)\n",
    "\n",
    "X_list, y_list = [], []\n",
    "for label, df in dfs.items():\n",
    "    Xw, yw = window_featurize(df, label)\n",
    "    X_list.append(Xw)\n",
    "    y_list.append(yw)\n",
    "\n",
    "X = np.vstack(X_list)\n",
    "y = np.concatenate(y_list)\n",
    "\n",
    "feature_names = [f\"{c}_{stat}\" for c in channels for stat in [\"mean\",\"std\",\"min\",\"max\",\"msq\"]]\n",
    "\n",
    "print(\"Total windows:\", X.shape[0], \"Feature dim:\", X.shape[1])\n",
    "print(\"Class counts:\", dict(zip(*np.unique(y, return_counts=True))))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3) Split 60% train, 20% val, 20% test (stratified)\n",
    "# ---------------------------------------------------------\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.40, random_state=42, stratify=y\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "# Encode labels to integers for ROC & log-loss tracking\n",
    "le = LabelEncoder()\n",
    "y_train_i = le.fit_transform(y_train)\n",
    "y_val_i   = le.transform(y_val)\n",
    "y_test_i  = le.transform(y_test)\n",
    "class_names = le.classes_.tolist()\n",
    "n_classes = len(class_names)\n",
    "\n",
    "# Scale features (important for MLP)\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_val_s   = scaler.transform(X_val)\n",
    "X_test_s  = scaler.transform(X_test)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4) MLP + Backprop training (explicit epoch loop using partial_fit)\n",
    "#    - This makes the \"Log Loss vs Epochs\" curve clear for students.\n",
    "# ---------------------------------------------------------\n",
    "# MLPClassifier uses backpropagation internally (gradient-based optimization).\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    alpha=1e-4,\n",
    "    learning_rate_init=1e-3,\n",
    "    max_iter=1,         # one \"epoch\" per partial_fit call\n",
    "    warm_start=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "EPOCHS = 120\n",
    "PATIENCE = 12\n",
    "\n",
    "train_ll, val_ll = [], []\n",
    "best_val = float(\"inf\")\n",
    "best_epoch = 0\n",
    "best_params = None\n",
    "pat = 0\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    # First call needs 'classes='\n",
    "    if epoch == 1:\n",
    "        mlp.partial_fit(X_train_s, y_train_i, classes=np.arange(n_classes))\n",
    "    else:\n",
    "        mlp.partial_fit(X_train_s, y_train_i)\n",
    "\n",
    "    # Track log-loss on train/val\n",
    "    p_tr = mlp.predict_proba(X_train_s)\n",
    "    p_va = mlp.predict_proba(X_val_s)\n",
    "    ll_tr = log_loss(y_train_i, p_tr, labels=np.arange(n_classes))\n",
    "    ll_va = log_loss(y_val_i, p_va, labels=np.arange(n_classes))\n",
    "\n",
    "    train_ll.append(ll_tr)\n",
    "    val_ll.append(ll_va)\n",
    "\n",
    "    # Early stopping\n",
    "    if ll_va + 1e-6 < best_val:\n",
    "        best_val = ll_va\n",
    "        best_epoch = epoch\n",
    "        best_params = mlp.coefs_, mlp.intercepts_\n",
    "        pat = 0\n",
    "    else:\n",
    "        pat += 1\n",
    "        if pat >= PATIENCE:\n",
    "            break\n",
    "\n",
    "# Restore best weights (so evaluation uses best validation point)\n",
    "if best_params is not None:\n",
    "    mlp.coefs_, mlp.intercepts_ = best_params\n",
    "\n",
    "print(f\"Stopped at epoch={len(train_ll)}; best epoch={best_epoch}, best val logloss={best_val:.4f}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 5) Evaluate on test set: Precision/Recall/Accuracy/F1\n",
    "# ---------------------------------------------------------\n",
    "y_pred = mlp.predict(X_test_s)\n",
    "p_test = mlp.predict_proba(X_test_s)\n",
    "\n",
    "acc  = accuracy_score(y_test_i, y_pred)\n",
    "prec = precision_score(y_test_i, y_pred, average=\"macro\", zero_division=0)\n",
    "rec  = recall_score(y_test_i, y_pred, average=\"macro\", zero_division=0)\n",
    "f1   = f1_score(y_test_i, y_pred, average=\"macro\", zero_division=0)\n",
    "cm   = confusion_matrix(y_test_i, y_pred)\n",
    "\n",
    "print(\"\\n=== Test Metrics (Macro Avg) ===\")\n",
    "print(\"Accuracy :\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall   :\", rec)\n",
    "print(\"F1-score :\", f1)\n",
    "\n",
    "print(\"\\nConfusion matrix (rows=true, cols=pred):\")\n",
    "print(pd.DataFrame(cm, index=[f\"true_{c}\" for c in class_names],\n",
    "                      columns=[f\"pred_{c}\" for c in class_names]))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 6) Save required visualizations with substring \"_mlpBP_\"\n",
    "# ---------------------------------------------------------\n",
    "out_dir = \"\"\n",
    "roc_path  = os.path.join(out_dir, \"roc_auc_mlpBP_test.png\")\n",
    "ll_path   = os.path.join(out_dir, \"logloss_mlpBP_epochs.png\")\n",
    "arch_path = os.path.join(out_dir, \"mlpBP_architecture_mlpBP.png\")\n",
    "w1_path   = os.path.join(out_dir, \"first_layer_weights_mlpBP.png\")\n",
    "\n",
    "# (A) ROC-AUC (One-vs-Rest)\n",
    "y_test_bin = label_binarize(y_test_i, classes=np.arange(n_classes))\n",
    "\n",
    "plt.figure()\n",
    "for i, name in enumerate(class_names):\n",
    "    fpr, tpr, _ = roc_curve(y_test_bin[:, i], p_test[:, i])\n",
    "    plt.plot(fpr, tpr, label=f\"{name} (AUC={auc(fpr,tpr):.2f})\")\n",
    "plt.plot([0, 1], [0, 1], \"--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curves (OvR) - MLP-BP - Test Set\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(roc_path, dpi=200)\n",
    "plt.show()\n",
    "\n",
    "# (B) Log Loss vs Epochs\n",
    "plt.figure()\n",
    "plt.plot(range(1, len(train_ll)+1), train_ll, label=\"Train log loss\")\n",
    "plt.plot(range(1, len(val_ll)+1), val_ll, label=\"Val log loss\")\n",
    "plt.axvline(best_epoch, linestyle=\"--\", label=f\"Best epoch={best_epoch}\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Log Loss\")\n",
    "plt.title(\"MLP-BP Log Loss vs Epochs\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(ll_path, dpi=200)\n",
    "plt.show()\n",
    "\n",
    "# (C) Model visualization: Architecture diagram (high-level)\n",
    "# Show up to 10 nodes per layer for readability\n",
    "input_dim = X.shape[1]\n",
    "hidden = (64, 32)\n",
    "output_dim = n_classes\n",
    "\n",
    "plt.figure(figsize=(9, 4))\n",
    "layers = [(\"Input\", min(10, input_dim)),\n",
    "          (\"H1\", min(10, hidden[0])),\n",
    "          (\"H2\", min(10, hidden[1])),\n",
    "          (\"Output\", output_dim)]\n",
    "xpos = np.linspace(0.1, 0.9, len(layers))\n",
    "\n",
    "for x, (lname, n) in zip(xpos, layers):\n",
    "    ys = np.linspace(0.1, 0.9, n)\n",
    "    for yv in ys:\n",
    "        plt.scatter([x], [yv], s=120)\n",
    "    shown = input_dim if lname == \"Input\" else (hidden[0] if lname==\"H1\" else (hidden[1] if lname==\"H2\" else output_dim))\n",
    "    plt.text(x, 0.95, f\"{lname}\\n({shown})\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "for li in range(len(layers)-1):\n",
    "    x1, x2 = xpos[li], xpos[li+1]\n",
    "    y1s = np.linspace(0.1, 0.9, layers[li][1])\n",
    "    y2s = np.linspace(0.1, 0.9, layers[li+1][1])\n",
    "    for a in y1s[:min(4,len(y1s))]:\n",
    "        for b in y2s[:min(4,len(y2s))]:\n",
    "            plt.plot([x1, x2], [a, b], linewidth=0.8, alpha=0.5)\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"MLP-BP Architecture (high-level visualization)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(arch_path, dpi=200)\n",
    "plt.show()\n",
    "\n",
    "# (D) Model-derived visualization: First-layer weight heatmap\n",
    "# coefs_[0] has shape (input_dim, hidden1); transpose to (hidden1, input_dim)\n",
    "W1 = mlp.coefs_[0].T\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.imshow(W1, aspect=\"auto\")\n",
    "plt.colorbar(label=\"Weight value\")\n",
    "plt.xlabel(\"Input feature index\")\n",
    "plt.ylabel(\"Hidden neuron index (H1)\")\n",
    "plt.title(\"First Layer Weights Heatmap (MLP-BP)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(w1_path, dpi=200)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSaved figures:\")\n",
    "print(\" \", roc_path)\n",
    "print(\" \", ll_path)\n",
    "print(\" \", arch_path)\n",
    "print(\" \", w1_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
