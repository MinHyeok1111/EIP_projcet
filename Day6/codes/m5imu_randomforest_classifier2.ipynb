{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28928ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, accuracy_score, f1_score,\n",
    "    confusion_matrix, roc_curve, auc, log_loss\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# ----------------------------\n",
    "# 1) File paths for 5 classes\n",
    "# ----------------------------\n",
    "paths = {\n",
    "    'bicep': 'imu_bicep_m0.csv',\n",
    "    'tricep': 'imu_tricep_m1.csv',\n",
    "    'overheadpress': 'imu_overheadpress_m2.csv',\n",
    "    'jump': 'imu_jump_m3.csv',\n",
    "    'squat': 'imu_squat_m4.csv'\n",
    "}\n",
    "\n",
    "# CSVs have no header row; enforce column names:\n",
    "colnames = [\"timestamp\",\"ax\",\"ay\",\"az\",\"gx\",\"gy\",\"gz\",\"roll\",\"pitch\",\"yaw\"]\n",
    "channels = [\"ax\",\"ay\",\"az\",\"gx\",\"gy\",\"gz\",\"roll\",\"pitch\",\"yaw\"]\n",
    "\n",
    "dfs = {label: pd.read_csv(p, header=None, names=colnames) for label, p in paths.items()}\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Windowing (100 Hz IMU)\n",
    "# ----------------------------\n",
    "FS = 100\n",
    "WIN = 100      # 1 second window\n",
    "STRIDE = 50    # 0.5 second overlap\n",
    "\n",
    "def window_featurize(df, label, win=WIN, stride=STRIDE):\n",
    "    \"\"\"\n",
    "    Convert a time-series file into windowed feature vectors.\n",
    "    Features per channel: mean, std, min, max, mean-square (energy proxy)\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for start in range(0, len(df) - win + 1, stride):\n",
    "        w = df.iloc[start:start+win]\n",
    "        feats = []\n",
    "        for c in channels:\n",
    "            x = w[c].astype(float).to_numpy()\n",
    "            feats.extend([\n",
    "                x.mean(),\n",
    "                x.std(ddof=0),\n",
    "                x.min(),\n",
    "                x.max(),\n",
    "                np.mean(x**2)\n",
    "            ])\n",
    "        X.append(feats)\n",
    "        y.append(label)\n",
    "    return np.array(X, dtype=np.float32), np.array(y)\n",
    "\n",
    "X_list, y_list = [], []\n",
    "for label, df in dfs.items():\n",
    "    Xw, yw = window_featurize(df, label)\n",
    "    X_list.append(Xw)\n",
    "    y_list.append(yw)\n",
    "\n",
    "X = np.vstack(X_list)\n",
    "y = np.concatenate(y_list)\n",
    "\n",
    "feature_names = [f\"{c}_{stat}\" for c in channels for stat in [\"mean\",\"std\",\"min\",\"max\",\"msq\"]]\n",
    "\n",
    "print(\"Total windows:\", X.shape[0], \"Feature dimension:\", X.shape[1])\n",
    "print(\"Class counts:\", dict(zip(*np.unique(y, return_counts=True))))\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Split 60/20/20\n",
    "# ----------------------------\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.40, random_state=42, stratify=y\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"Split sizes:\", len(y_train), len(y_val), len(y_test))\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Hyperparameter sweep (tune by validation log loss)\n",
    "# ----------------------------\n",
    "n_estimators_grid = [50, 100, 200]\n",
    "max_depth_grid = [None, 3, 5, 8, 12]\n",
    "\n",
    "best = None\n",
    "records = []\n",
    "\n",
    "for n_est in n_estimators_grid:\n",
    "    for md in max_depth_grid:\n",
    "        rf_try = RandomForestClassifier(\n",
    "            n_estimators=n_est,\n",
    "            max_depth=md,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        rf_try.fit(X_train, y_train)\n",
    "        val_proba = rf_try.predict_proba(X_val)\n",
    "        ll = log_loss(y_val, val_proba, labels=rf_try.classes_)\n",
    "\n",
    "        records.append({\"n_estimators\": n_est, \"max_depth\": str(md), \"val_log_loss\": ll})\n",
    "        if best is None or ll < best[\"val_log_loss\"]:\n",
    "            best = {\"n_estimators\": n_est, \"max_depth\": md, \"val_log_loss\": ll}\n",
    "\n",
    "tune_df = pd.DataFrame(records).sort_values(\"val_log_loss\").reset_index(drop=True)\n",
    "print(\"\\nTop sweep results:\\n\", tune_df.head(10))\n",
    "print(\"\\nBest params:\", best)\n",
    "\n",
    "# Train final RF\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=best[\"n_estimators\"],\n",
    "    max_depth=best[\"max_depth\"],\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# ----------------------------\n",
    "# 5) Test metrics\n",
    "# ----------------------------\n",
    "y_pred = rf.predict(X_test)\n",
    "proba = rf.predict_proba(X_test)\n",
    "labels = list(rf.classes_)\n",
    "\n",
    "acc  = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "rec  = recall_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "f1   = f1_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "ll   = log_loss(y_test, proba, labels=labels)\n",
    "\n",
    "print(\"\\n=== Test Metrics (Macro Avg) ===\")\n",
    "print(\"Accuracy :\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall   :\", rec)\n",
    "print(\"F1-score :\", f1)\n",
    "print(\"Log Loss :\", ll)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "print(\"\\nConfusion matrix (rows=true, cols=pred), labels =\", labels)\n",
    "print(cm)\n",
    "\n",
    "# ----------------------------\n",
    "# 6) Save visuals (must include '_rf_')\n",
    "# ----------------------------\n",
    "out_dir = \"\"\n",
    "roc_path  = os.path.join(out_dir, \"roc_auc_rf_test.png\")\n",
    "ll_path   = os.path.join(out_dir, \"logloss_rf_sweep.png\")\n",
    "imp_path  = os.path.join(out_dir, \"feature_importance_rf.png\")\n",
    "tree_path = os.path.join(out_dir, \"one_tree_rf.png\")\n",
    "\n",
    "# ROC-AUC curves (multiclass one-vs-rest)\n",
    "y_test_bin = label_binarize(y_test, classes=labels)\n",
    "\n",
    "plt.figure()\n",
    "for i, lab in enumerate(labels):\n",
    "    fpr, tpr, _ = roc_curve(y_test_bin[:, i], proba[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f\"{lab} (AUC={roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], \"--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curves (One-vs-Rest) - Random Forest - Test Set\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(roc_path, dpi=200)\n",
    "plt.show()\n",
    "\n",
    "# Log loss curve for sweep results\n",
    "plt.figure()\n",
    "for n_est in n_estimators_grid:\n",
    "    sub = tune_df[tune_df[\"n_estimators\"] == n_est].copy()\n",
    "\n",
    "    def md_to_num(v):\n",
    "        return 999 if v == \"None\" else int(v)\n",
    "\n",
    "    sub[\"md_num\"] = sub[\"max_depth\"].apply(md_to_num)\n",
    "    sub = sub.sort_values(\"md_num\")\n",
    "\n",
    "    plt.plot(sub[\"md_num\"], sub[\"val_log_loss\"], marker=\"o\", label=f\"n_estimators={n_est}\")\n",
    "\n",
    "plt.xlabel(\"max_depth (None shown as 999)\")\n",
    "plt.ylabel(\"Validation Log Loss\")\n",
    "plt.title(\"RF Validation Log Loss vs max_depth (sweep)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(ll_path, dpi=200)\n",
    "plt.show()\n",
    "\n",
    "# Feature importances (Top 15)\n",
    "importances = rf.feature_importances_\n",
    "idx = np.argsort(importances)[::-1][:15]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(len(idx)), importances[idx])\n",
    "plt.xticks(range(len(idx)), [feature_names[i] for i in idx], rotation=45, ha=\"right\")\n",
    "plt.title(\"Random Forest Feature Importances (Top 15)\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(imp_path, dpi=200)\n",
    "plt.show()\n",
    "\n",
    "# Visualize one representative tree (tree #0) from the forest\n",
    "est0 = rf.estimators_[0]\n",
    "plt.figure(figsize=(22, 10))\n",
    "plot_tree(\n",
    "    est0,\n",
    "    feature_names=feature_names,\n",
    "    class_names=labels,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    fontsize=7,\n",
    "    max_depth=4\n",
    ")\n",
    "plt.title(\"One Tree from the Random Forest (Top Levels)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(tree_path, dpi=200)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSaved figures:\")\n",
    "print(\" \", roc_path)\n",
    "print(\" \", ll_path)\n",
    "print(\" \", imp_path)\n",
    "print(\" \", tree_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
